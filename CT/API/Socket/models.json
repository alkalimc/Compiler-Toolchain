[
  {
    "name": "glm",
    "model": "glm",
    "api": "openai",
    "parameters": {
      "temperature": 0.7,
      "top_p": 0.9,
      "max_tokens": 2048
    }
  }
]